{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f05f6afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\breath03\\AppData\\Local\\Temp\\ipykernel_18652\\3686205631.py:3: DtypeWarning: Columns (25,62,89,229,230,231,232,233,234,235,236,237,340,342,343,344,345,347,348,349,508,707,708) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_df = pd.read_csv('C:/Users/breath03/Desktop/Smart_Closet/labeled_fashion_data.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21240, 1189)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('C:/Users/breath03/Desktop/Smart_Closet/labeled_fashion_data.csv')\n",
    "# print(train_df.head())\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19b0a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 'ì•„ìš°í„°' ì¹´í…Œê³ ë¦¬ í´ë¦¬ê³¤ í”¼ì²˜ ìƒì„± ì‹œì‘ ---\n",
      "'ì•„ìš°í„°' ì¹´í…Œê³ ë¦¬ ì²˜ë¦¬ ì™„ë£Œ.\n",
      "--- 'í•˜ì˜' ì¹´í…Œê³ ë¦¬ í´ë¦¬ê³¤ í”¼ì²˜ ìƒì„± ì‹œì‘ ---\n",
      "'í•˜ì˜' ì¹´í…Œê³ ë¦¬ ì²˜ë¦¬ ì™„ë£Œ.\n",
      "--- 'ì›í”¼ìŠ¤' ì¹´í…Œê³ ë¦¬ í´ë¦¬ê³¤ í”¼ì²˜ ìƒì„± ì‹œì‘ ---\n",
      "'ì›í”¼ìŠ¤' ì¹´í…Œê³ ë¦¬ ì²˜ë¦¬ ì™„ë£Œ.\n",
      "--- 'ìƒì˜' ì¹´í…Œê³ ë¦¬ í´ë¦¬ê³¤ í”¼ì²˜ ìƒì„± ì‹œì‘ ---\n",
      "'ìƒì˜' ì¹´í…Œê³ ë¦¬ ì²˜ë¦¬ ì™„ë£Œ.\n",
      "\n",
      "--- ë¶ˆí•„ìš”í•œ ì›ë³¸ í´ë¦¬ê³¤ ì¢Œí‘œ ì»¬ëŸ¼ ì „ì²´ ì‚­ì œ ì¤‘ ---\n",
      "\n",
      "ìµœì¢… DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21240 entries, 0 to 21239\n",
      "Data columns (total 89 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   ì´ë¯¸ì§€ ì‹ë³„ì        21240 non-null  int64  \n",
      " 1   ì´ë¯¸ì§€ ë†’ì´         21240 non-null  int64  \n",
      " 2   ì´ë¯¸ì§€ íŒŒì¼ëª…        21240 non-null  object \n",
      " 3   ì´ë¯¸ì§€ ë„ˆë¹„         21240 non-null  int64  \n",
      " 4   íŒŒì¼ ìƒì„±ì¼ì        21240 non-null  object \n",
      " 5   ì¹´í…Œê³ ë¦¬           21240 non-null  object \n",
      " 6   ìŠ¤íƒ€ì¼_ìŠ¤íƒ€ì¼        21240 non-null  object \n",
      " 7   í•˜ì˜_ë ‰íŠ¸_Xì¢Œí‘œ      11399 non-null  float64\n",
      " 8   í•˜ì˜_ë ‰íŠ¸_Yì¢Œí‘œ      11399 non-null  float64\n",
      " 9   í•˜ì˜_ë ‰íŠ¸_ê°€ë¡œ       11399 non-null  float64\n",
      " 10  í•˜ì˜_ë ‰íŠ¸_ì„¸ë¡œ       11399 non-null  float64\n",
      " 11  í•˜ì˜_ë¼ë²¨_ê¸°ì¥       11359 non-null  object \n",
      " 12  í•˜ì˜_ë¼ë²¨_ìƒ‰ìƒ       11687 non-null  object \n",
      " 13  í•˜ì˜_ë¼ë²¨_ì„œë¸Œìƒ‰ìƒ     1380 non-null   object \n",
      " 14  í•˜ì˜_ë¼ë²¨_ì¹´í…Œê³ ë¦¬     11793 non-null  object \n",
      " 15  í•˜ì˜_ë¼ë²¨_ì†Œì¬       11229 non-null  object \n",
      " 16  í•˜ì˜_ë¼ë²¨_í”„ë¦°íŠ¸      10216 non-null  object \n",
      " 17  í•˜ì˜_ë¼ë²¨_í•        11370 non-null  object \n",
      " 18  ìƒì˜_ë ‰íŠ¸_Xì¢Œí‘œ      12717 non-null  float64\n",
      " 19  ìƒì˜_ë ‰íŠ¸_Yì¢Œí‘œ      12717 non-null  float64\n",
      " 20  ìƒì˜_ë ‰íŠ¸_ê°€ë¡œ       12717 non-null  float64\n",
      " 21  ìƒì˜_ë ‰íŠ¸_ì„¸ë¡œ       12717 non-null  float64\n",
      " 22  ìƒì˜_ë¼ë²¨_ê¸°ì¥       8518 non-null   object \n",
      " 23  ìƒì˜_ë¼ë²¨_ìƒ‰ìƒ       12773 non-null  object \n",
      " 24  ìƒì˜_ë¼ë²¨_ì„œë¸Œìƒ‰ìƒ     3996 non-null   object \n",
      " 25  ìƒì˜_ë¼ë²¨_ì¹´í…Œê³ ë¦¬     12786 non-null  object \n",
      " 26  ìƒì˜_ë¼ë²¨_ì˜·ê¹ƒ       1777 non-null   object \n",
      " 27  ìƒì˜_ë¼ë²¨_ì†Œë§¤ê¸°ì¥     12773 non-null  object \n",
      " 28  ìƒì˜_ë¼ë²¨_ì†Œì¬       12034 non-null  object \n",
      " 29  ìƒì˜_ë¼ë²¨_í”„ë¦°íŠ¸      11326 non-null  object \n",
      " 30  ìƒì˜_ë¼ë²¨_ë„¥ë¼ì¸      9762 non-null   object \n",
      " 31  ìƒì˜_ë¼ë²¨_í•        12530 non-null  object \n",
      " 32  ìƒì˜_ë¼ë²¨_ë””í…Œì¼      5978 non-null   object \n",
      " 33  í•˜ì˜_ë¼ë²¨_ë””í…Œì¼      4382 non-null   object \n",
      " 34  ìŠ¤íƒ€ì¼_ì„œë¸ŒìŠ¤íƒ€ì¼      10445 non-null  object \n",
      " 35  ì›í”¼ìŠ¤_ë ‰íŠ¸_Xì¢Œí‘œ     4238 non-null   float64\n",
      " 36  ì›í”¼ìŠ¤_ë ‰íŠ¸_Yì¢Œí‘œ     4238 non-null   float64\n",
      " 37  ì›í”¼ìŠ¤_ë ‰íŠ¸_ê°€ë¡œ      4238 non-null   float64\n",
      " 38  ì›í”¼ìŠ¤_ë ‰íŠ¸_ì„¸ë¡œ      4238 non-null   float64\n",
      " 39  ì›í”¼ìŠ¤_ë¼ë²¨_ê¸°ì¥      4195 non-null   object \n",
      " 40  ì›í”¼ìŠ¤_ë¼ë²¨_ìƒ‰ìƒ      4139 non-null   object \n",
      " 41  ì›í”¼ìŠ¤_ë¼ë²¨_ì¹´í…Œê³ ë¦¬    4261 non-null   object \n",
      " 42  ì›í”¼ìŠ¤_ë¼ë²¨_ë””í…Œì¼     3376 non-null   object \n",
      " 43  ì›í”¼ìŠ¤_ë¼ë²¨_ì†Œë§¤ê¸°ì¥    4139 non-null   object \n",
      " 44  ì›í”¼ìŠ¤_ë¼ë²¨_ì†Œì¬      4048 non-null   object \n",
      " 45  ì›í”¼ìŠ¤_ë¼ë²¨_í”„ë¦°íŠ¸     3793 non-null   object \n",
      " 46  ì›í”¼ìŠ¤_ë¼ë²¨_ë„¥ë¼ì¸     2739 non-null   object \n",
      " 47  ì›í”¼ìŠ¤_ë¼ë²¨_í•       4177 non-null   object \n",
      " 48  ì•„ìš°í„°_ë ‰íŠ¸_Xì¢Œí‘œ     4808 non-null   float64\n",
      " 49  ì•„ìš°í„°_ë ‰íŠ¸_Yì¢Œí‘œ     4808 non-null   float64\n",
      " 50  ì•„ìš°í„°_ë ‰íŠ¸_ê°€ë¡œ      4808 non-null   float64\n",
      " 51  ì•„ìš°í„°_ë ‰íŠ¸_ì„¸ë¡œ      4808 non-null   float64\n",
      " 52  ì•„ìš°í„°_ë¼ë²¨_ê¸°ì¥      4791 non-null   object \n",
      " 53  ì•„ìš°í„°_ë¼ë²¨_ìƒ‰ìƒ      4804 non-null   object \n",
      " 54  ì•„ìš°í„°_ë¼ë²¨_ì„œë¸Œìƒ‰ìƒ    1300 non-null   object \n",
      " 55  ì•„ìš°í„°_ë¼ë²¨_ì¹´í…Œê³ ë¦¬    4911 non-null   object \n",
      " 56  ì•„ìš°í„°_ë¼ë²¨_ì˜·ê¹ƒ      2861 non-null   object \n",
      " 57  ì•„ìš°í„°_ë¼ë²¨_ë””í…Œì¼     3250 non-null   object \n",
      " 58  ì•„ìš°í„°_ë¼ë²¨_ì†Œë§¤ê¸°ì¥    4804 non-null   object \n",
      " 59  ì•„ìš°í„°_ë¼ë²¨_ì†Œì¬      4754 non-null   object \n",
      " 60  ì•„ìš°í„°_ë¼ë²¨_í”„ë¦°íŠ¸     4378 non-null   object \n",
      " 61  ì•„ìš°í„°_ë¼ë²¨_í•       4897 non-null   object \n",
      " 62  ì•„ìš°í„°_ë¼ë²¨_ë„¥ë¼ì¸     1665 non-null   object \n",
      " 63  ì›í”¼ìŠ¤_ë¼ë²¨_ì˜·ê¹ƒ      970 non-null    object \n",
      " 64  ì›í”¼ìŠ¤_ë¼ë²¨_ì„œë¸Œìƒ‰ìƒ    1490 non-null   object \n",
      " 65  ì•„ìš°í„°_í´ë¦¬ê³¤_ë©´ì      21240 non-null  float64\n",
      " 66  ì•„ìš°í„°_í´ë¦¬ê³¤_ë„ˆë¹„     21240 non-null  float64\n",
      " 67  ì•„ìš°í„°_í´ë¦¬ê³¤_ë†’ì´     21240 non-null  float64\n",
      " 68  ì•„ìš°í„°_í´ë¦¬ê³¤_ê°€ë¡œì„¸ë¡œë¹„  21240 non-null  float64\n",
      " 69  ì•„ìš°í„°_í´ë¦¬ê³¤_ì¤‘ì‹¬X    21240 non-null  float64\n",
      " 70  ì•„ìš°í„°_í´ë¦¬ê³¤_ì¤‘ì‹¬Y    21240 non-null  float64\n",
      " 71  í•˜ì˜_í´ë¦¬ê³¤_ë©´ì       21240 non-null  float64\n",
      " 72  í•˜ì˜_í´ë¦¬ê³¤_ë„ˆë¹„      21240 non-null  float64\n",
      " 73  í•˜ì˜_í´ë¦¬ê³¤_ë†’ì´      21240 non-null  float64\n",
      " 74  í•˜ì˜_í´ë¦¬ê³¤_ê°€ë¡œì„¸ë¡œë¹„   21240 non-null  float64\n",
      " 75  í•˜ì˜_í´ë¦¬ê³¤_ì¤‘ì‹¬X     21240 non-null  float64\n",
      " 76  í•˜ì˜_í´ë¦¬ê³¤_ì¤‘ì‹¬Y     21240 non-null  float64\n",
      " 77  ì›í”¼ìŠ¤_í´ë¦¬ê³¤_ë©´ì      21240 non-null  float64\n",
      " 78  ì›í”¼ìŠ¤_í´ë¦¬ê³¤_ë„ˆë¹„     21240 non-null  float64\n",
      " 79  ì›í”¼ìŠ¤_í´ë¦¬ê³¤_ë†’ì´     21240 non-null  float64\n",
      " 80  ì›í”¼ìŠ¤_í´ë¦¬ê³¤_ê°€ë¡œì„¸ë¡œë¹„  21240 non-null  float64\n",
      " 81  ì›í”¼ìŠ¤_í´ë¦¬ê³¤_ì¤‘ì‹¬X    21240 non-null  float64\n",
      " 82  ì›í”¼ìŠ¤_í´ë¦¬ê³¤_ì¤‘ì‹¬Y    21240 non-null  float64\n",
      " 83  ìƒì˜_í´ë¦¬ê³¤_ë©´ì       21240 non-null  float64\n",
      " 84  ìƒì˜_í´ë¦¬ê³¤_ë„ˆë¹„      21240 non-null  float64\n",
      " 85  ìƒì˜_í´ë¦¬ê³¤_ë†’ì´      21240 non-null  float64\n",
      " 86  ìƒì˜_í´ë¦¬ê³¤_ê°€ë¡œì„¸ë¡œë¹„   21240 non-null  float64\n",
      " 87  ìƒì˜_í´ë¦¬ê³¤_ì¤‘ì‹¬X     21240 non-null  float64\n",
      " 88  ìƒì˜_í´ë¦¬ê³¤_ì¤‘ì‹¬Y     21240 non-null  float64\n",
      "dtypes: float64(40), int64(3), object(46)\n",
      "memory usage: 14.4+ MB\n",
      "\n",
      "ìƒˆë¡­ê²Œ ìƒì„±ëœ í”¼ì²˜ í™•ì¸ (ìƒìœ„ 5ê°œ):\n",
      "   ì´ë¯¸ì§€ ì‹ë³„ì  ì•„ìš°í„°_í´ë¦¬ê³¤_ë©´ì   ì•„ìš°í„°_í´ë¦¬ê³¤_ë„ˆë¹„  ì•„ìš°í„°_í´ë¦¬ê³¤_ë†’ì´  ì•„ìš°í„°_í´ë¦¬ê³¤_ê°€ë¡œì„¸ë¡œë¹„  ì•„ìš°í„°_í´ë¦¬ê³¤_ì¤‘ì‹¬X  \\\n",
      "0   100026         0.0         0.0         0.0            0.0          0.0   \n",
      "1   100027         0.0         0.0         0.0            0.0          0.0   \n",
      "2   100028         0.0         0.0         0.0            0.0          0.0   \n",
      "3   100029         0.0         0.0         0.0            0.0          0.0   \n",
      "4   100030         0.0         0.0         0.0            0.0          0.0   \n",
      "\n",
      "   ì•„ìš°í„°_í´ë¦¬ê³¤_ì¤‘ì‹¬Y      í•˜ì˜_í´ë¦¬ê³¤_ë©´ì   í•˜ì˜_í´ë¦¬ê³¤_ë„ˆë¹„  í•˜ì˜_í´ë¦¬ê³¤_ë†’ì´  ...  ì›í”¼ìŠ¤_í´ë¦¬ê³¤_ë†’ì´  \\\n",
      "0          0.0   56680.718229    183.744    330.763  ...         0.0   \n",
      "1          0.0  105402.033488    263.633    427.405  ...         0.0   \n",
      "2          0.0       0.000000      0.000      0.000  ...         0.0   \n",
      "3          0.0  110468.115532    282.607    446.379  ...         0.0   \n",
      "4          0.0       0.000000      0.000      0.000  ...         0.0   \n",
      "\n",
      "   ì›í”¼ìŠ¤_í´ë¦¬ê³¤_ê°€ë¡œì„¸ë¡œë¹„  ì›í”¼ìŠ¤_í´ë¦¬ê³¤_ì¤‘ì‹¬X  ì›í”¼ìŠ¤_í´ë¦¬ê³¤_ì¤‘ì‹¬Y      ìƒì˜_í´ë¦¬ê³¤_ë©´ì   ìƒì˜_í´ë¦¬ê³¤_ë„ˆë¹„  \\\n",
      "0            0.0          0.0          0.0   72177.663165    295.589   \n",
      "1            0.0          0.0          0.0  147509.174491    453.370   \n",
      "2            0.0          0.0          0.0  165681.753805    420.415   \n",
      "3            0.0          0.0          0.0  151037.731548    391.456   \n",
      "4            0.0          0.0          0.0  157837.291095    378.474   \n",
      "\n",
      "   ìƒì˜_í´ë¦¬ê³¤_ë†’ì´  ìƒì˜_í´ë¦¬ê³¤_ê°€ë¡œì„¸ë¡œë¹„  ìƒì˜_í´ë¦¬ê³¤_ì¤‘ì‹¬X  ìƒì˜_í´ë¦¬ê³¤_ì¤‘ì‹¬Y  \n",
      "0   335.5334      0.880953  403.049226  217.499630  \n",
      "1   468.4593      0.967790  416.075928  274.264583  \n",
      "2   523.4941      0.803094  309.704701  331.085999  \n",
      "3   493.3139      0.793523  533.755801  304.118779  \n",
      "4   574.4235      0.658876  378.014366  346.906751  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "'labeled_fashion_data(polygon_features).csv' íŒŒì¼ë¡œ ì €ì¥ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# í´ë¦¬ê³¤ì— ëŒ€í•œ ê°’ì„ ê³„ì‚°í•´ì„œ ìƒˆë¡œìš´ í”¼ì²˜ë¡œ ì¶”ê°€í•˜ëŠ” ì½”ë“œ\n",
    "\n",
    "import pandas as pd\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "# --- í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ì„ ì ìš©í•  ì˜ë¥˜ ì¹´í…Œê³ ë¦¬ ëª©ë¡ ---\n",
    "clothing_parts = [\"ì•„ìš°í„°\", \"í•˜ì˜\", \"ì›í”¼ìŠ¤\", \"ìƒì˜\"]\n",
    "\n",
    "# ì‚­ì œí•  ì›ë³¸ í´ë¦¬ê³¤ ì»¬ëŸ¼ë“¤ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
    "all_poly_cols_to_drop = []\n",
    "\n",
    "# ê° ì˜ë¥˜ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë°˜ë³µ ì‘ì—… ìˆ˜í–‰\n",
    "for part in clothing_parts:\n",
    "    print(f\"--- '{part}' ì¹´í…Œê³ ë¦¬ í´ë¦¬ê³¤ í”¼ì²˜ ìƒì„± ì‹œì‘ ---\")\n",
    "\n",
    "    # 1. í˜„ì¬ ì¹´í…Œê³ ë¦¬ì— í•´ë‹¹í•˜ëŠ” í´ë¦¬ê³¤ ì¢Œí‘œ ì»¬ëŸ¼ ì´ë¦„ë“¤ì„ ë™ì ìœ¼ë¡œ ì°¾ê¸°\n",
    "    # ì˜ˆ: partê°€ 'ìƒì˜'ì´ë©´ 'ìƒì˜_í´ë¦¬ê³¤_Xì¢Œí‘œ'ê°€ í¬í•¨ëœ ì»¬ëŸ¼ì„ ì°¾ìŒ\n",
    "    poly_x_cols = sorted([col for col in train_df.columns if f'{part}_í´ë¦¬ê³¤_Xì¢Œí‘œ' in col])\n",
    "    poly_y_cols = sorted([col for col in train_df.columns if f'{part}_í´ë¦¬ê³¤_Yì¢Œí‘œ' in col])\n",
    "    \n",
    "    # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ í´ë¦¬ê³¤ ì¢Œí‘œ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ë¡œ ë„˜ì–´ê°\n",
    "    if not poly_x_cols:\n",
    "        print(f\"'{part}' ì¹´í…Œê³ ë¦¬ì— ëŒ€í•œ í´ë¦¬ê³¤ ì¢Œí‘œ ì •ë³´ê°€ ì—†ì–´ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "        continue\n",
    "\n",
    "    # ì‚­ì œ ë¦¬ìŠ¤íŠ¸ì— í˜„ì¬ ì¢Œí‘œ ì»¬ëŸ¼ë“¤ ì¶”ê°€\n",
    "    all_poly_cols_to_drop.extend(poly_x_cols)\n",
    "    all_poly_cols_to_drop.extend(poly_y_cols)\n",
    "    \n",
    "    # ê° í–‰(ì´ë¯¸ì§€)ë§ˆë‹¤ (X, Y) ì¢Œí‘œ ìŒ ë¦¬ìŠ¤íŠ¸ë¥¼ ë§Œë“œëŠ” í•¨ìˆ˜ (ì¬ì‚¬ìš©)\n",
    "    def create_polygon_points(row, x_cols, y_cols):\n",
    "        points = []\n",
    "        for x_col, y_col in zip(x_cols, y_cols):\n",
    "            if pd.notna(row[x_col]) and pd.notna(row[y_col]):\n",
    "                points.append((row[x_col], row[y_col]))\n",
    "        if len(points) >= 3:\n",
    "            return Polygon(points)\n",
    "        return None\n",
    "\n",
    "    # ì„ì‹œ 'polygon' ì»¬ëŸ¼ ìƒì„±\n",
    "    temp_polygon_col = f'{part}_polygon'\n",
    "    train_df[temp_polygon_col] = train_df.apply(lambda row: create_polygon_points(row, poly_x_cols, poly_y_cols), axis=1)\n",
    "\n",
    "    # 2. ìƒˆë¡œìš´ í”¼ì²˜(Feature)ë¥¼ ë™ì  ì»¬ëŸ¼ëª…ìœ¼ë¡œ ê³„ì‚° ë° ì¶”ê°€\n",
    "    train_df[f'{part}_í´ë¦¬ê³¤_ë©´ì '] = train_df[temp_polygon_col].apply(lambda p: p.area if p else 0)\n",
    "\n",
    "    def get_bbox_features(p):\n",
    "        if p:\n",
    "            minx, miny, maxx, maxy = p.bounds\n",
    "            width = maxx - minx\n",
    "            height = maxy - miny\n",
    "            aspect_ratio = width / height if height > 0 else 0\n",
    "            return width, height, aspect_ratio\n",
    "        return 0, 0, 0\n",
    "\n",
    "    bbox_features = train_df[temp_polygon_col].apply(get_bbox_features)\n",
    "    train_df[[f'{part}_í´ë¦¬ê³¤_ë„ˆë¹„', f'{part}_í´ë¦¬ê³¤_ë†’ì´', f'{part}_í´ë¦¬ê³¤_ê°€ë¡œì„¸ë¡œë¹„']] = pd.DataFrame(bbox_features.tolist(), index=train_df.index)\n",
    "\n",
    "    train_df[f'{part}_í´ë¦¬ê³¤_ì¤‘ì‹¬X'] = train_df[temp_polygon_col].apply(lambda p: p.centroid.x if p else 0)\n",
    "    train_df[f'{part}_í´ë¦¬ê³¤_ì¤‘ì‹¬Y'] = train_df[temp_polygon_col].apply(lambda p: p.centroid.y if p else 0)\n",
    "    \n",
    "    # ì„ì‹œ polygon ì»¬ëŸ¼ì€ ì‚­ì œ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "    all_poly_cols_to_drop.append(temp_polygon_col)\n",
    "    print(f\"'{part}' ì¹´í…Œê³ ë¦¬ ì²˜ë¦¬ ì™„ë£Œ.\")\n",
    "\n",
    "\n",
    "# 3. ëª¨ë“  ì›ë³¸ í´ë¦¬ê³¤ ì¢Œí‘œ ì»¬ëŸ¼ ë° ì„ì‹œ ì»¬ëŸ¼ë“¤ì„ í•œ ë²ˆì— ì œê±°\n",
    "print(\"\\n--- ë¶ˆí•„ìš”í•œ ì›ë³¸ í´ë¦¬ê³¤ ì¢Œí‘œ ì»¬ëŸ¼ ì „ì²´ ì‚­ì œ ì¤‘ ---\")\n",
    "train_df.drop(columns=all_poly_cols_to_drop, inplace=True, errors='ignore')\n",
    "\n",
    "# ê²°ê³¼ í™•ì¸\n",
    "print(\"\\nìµœì¢… DataFrame Info:\")\n",
    "train_df.info()\n",
    "\n",
    "# ìƒì„±ëœ í”¼ì²˜ ì¤‘ ì¼ë¶€ë¥¼ í™•ì¸\n",
    "print(\"\\nìƒˆë¡­ê²Œ ìƒì„±ëœ í”¼ì²˜ í™•ì¸ (ìƒìœ„ 5ê°œ):\")\n",
    "new_feature_cols = [col for col in train_df.columns if '_í´ë¦¬ê³¤_' in col]\n",
    "print(train_df[['ì´ë¯¸ì§€ ì‹ë³„ì'] + new_feature_cols].head())\n",
    "\n",
    "# íŒŒì¼ë¡œ ì €ì¥\n",
    "train_df.to_csv('labeled_fashion_data(polygon_features).csv', index=False, encoding='utf-8-sig')\n",
    "print(\"\\n'labeled_fashion_data(polygon_features).csv' íŒŒì¼ë¡œ ì €ì¥ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2205e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'C:/Users/breath03/Desktop/Smart_Closet/labeled_fashion_data(polygon_features).csv' íŒŒì¼ì„ ì½ëŠ” ì¤‘ì…ë‹ˆë‹¤...\n",
      "YOLO í•™ìŠµì— í•„ìš”í•œ ë°ì´í„° ì¶”ì¶œì„ ì‹œì‘í•©ë‹ˆë‹¤...\n",
      "ì¶”ì¶œ ì™„ë£Œ! 'train_yolo_df' ë°ì´í„°í”„ë ˆì„ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ìƒì„±ëœ train_yolo_df ë¯¸ë¦¬ë³´ê¸°:\n",
      "  image_identifier  image_width  image_height class        x         y  width  \\\n",
      "0           100026          800           800    ìƒì˜  260.144   59.4236  295.0   \n",
      "1           100026          800           800    í•˜ì˜  321.060  288.2160  183.0   \n",
      "2           100027          800           800    ìƒì˜  188.244   51.4347  453.0   \n",
      "3           100027          800           800    í•˜ì˜  285.110  369.2150  263.0   \n",
      "4           100028          800           800    ìƒì˜  100.367   71.4069  420.0   \n",
      "\n",
      "   height  \n",
      "0   335.0  \n",
      "1   330.0  \n",
      "2   468.0  \n",
      "3   427.0  \n",
      "4   523.0  \n",
      "\n",
      "í´ë˜ìŠ¤ ë§¤í•‘ ì •ë³´:\n",
      "{'ìƒì˜': 0, 'í•˜ì˜': 1, 'ì›í”¼ìŠ¤': 2, 'ì•„ìš°í„°': 3}\n",
      "\n",
      "'yolo_labels' í´ë”ì— YOLO ë¼ë²¨ íŒŒì¼ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤...\n",
      "ë¼ë²¨ íŒŒì¼ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ 21039ê°œì˜ íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "--- YOLO í•™ìŠµìš© YAML íŒŒì¼ì— ë‹¤ìŒ ë‚´ìš©ì„ ì¶”ê°€í•˜ì„¸ìš” ---\n",
      "names:\n",
      "  0: ìƒì˜\n",
      "  1: í•˜ì˜\n",
      "  2: ì›í”¼ìŠ¤\n",
      "  3: ì•„ìš°í„°\n",
      "nc: 4\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# yolo í•™ìŠµì— í•„ìš”í•œ .txtíŒŒì¼ ìƒì„± ì½”ë“œ\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def create_yolo_dataframe(csv_path):\n",
    "    \"\"\"\n",
    "    ì›ë³¸ CSV íŒŒì¼ì—ì„œ YOLO í•™ìŠµì— í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì¶”ì¶œí•˜ì—¬\n",
    "    ìƒˆë¡œìš´ ë°ì´í„°í”„ë ˆì„(train_yolo_df)ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    print(f\"'{csv_path}' íŒŒì¼ì„ ì½ëŠ” ì¤‘ì…ë‹ˆë‹¤...\")\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ì˜¤ë¥˜: '{csv_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return None\n",
    "\n",
    "    # YOLO í•™ìŠµì— í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ë‹´ì„ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”\n",
    "    yolo_data_list = []\n",
    "    item_types = ['ìƒì˜', 'í•˜ì˜', 'ì•„ìš°í„°', 'ì›í”¼ìŠ¤']\n",
    "\n",
    "    print(\"YOLO í•™ìŠµì— í•„ìš”í•œ ë°ì´í„° ì¶”ì¶œì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "    # ì›ë³¸ ë°ì´í„°í”„ë ˆì„ ìˆœíšŒ\n",
    "    for index, row in df.iterrows():\n",
    "        image_identifier = str(row['ì´ë¯¸ì§€ ì‹ë³„ì'])\n",
    "        image_width = row['ì´ë¯¸ì§€ ë„ˆë¹„']\n",
    "        image_height = row['ì´ë¯¸ì§€ ë†’ì´']\n",
    "\n",
    "        for item_type in item_types:\n",
    "            x_col, y_col, w_col, h_col = f'{item_type}_ë ‰íŠ¸_Xì¢Œí‘œ', f'{item_type}_ë ‰íŠ¸_Yì¢Œí‘œ', f'{item_type}_ë ‰íŠ¸_ê°€ë¡œ', f'{item_type}_ë ‰íŠ¸_ì„¸ë¡œ'\n",
    "\n",
    "            # í•´ë‹¹ ì•„ì´í…œì˜ ì¢Œí‘œ ì •ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸ (0ë³´ë‹¤ í° ê²½ìš°)\n",
    "            if x_col in row and row.get(x_col, 0) > 0:\n",
    "                yolo_data_list.append({\n",
    "                    'image_identifier': image_identifier,\n",
    "                    'image_width': image_width,\n",
    "                    'image_height': image_height,\n",
    "                    'class': item_type,\n",
    "                    'x': row[x_col],\n",
    "                    'y': row[y_col],\n",
    "                    'width': row[w_col],\n",
    "                    'height': row[h_col]\n",
    "                })\n",
    "\n",
    "    # ìƒˆë¡œìš´ ë°ì´í„°í”„ë ˆì„ ìƒì„±\n",
    "    train_yolo_df = pd.DataFrame(yolo_data_list)\n",
    "    print(\"ì¶”ì¶œ ì™„ë£Œ! 'train_yolo_df' ë°ì´í„°í”„ë ˆì„ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.\")\n",
    "    return train_yolo_df\n",
    "\n",
    "\n",
    "def create_yolo_label_files(yolo_df, output_dir='labels'):\n",
    "    \"\"\"\n",
    "    train_yolo_dfë¥¼ ì…ë ¥ë°›ì•„ YOLO í˜•ì‹ì˜ .txt ë¼ë²¨ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    if yolo_df is None or yolo_df.empty:\n",
    "        print(\"ë°ì´í„°í”„ë ˆì„ì´ ë¹„ì–´ìˆì–´ ë¼ë²¨ íŒŒì¼ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    # ë¼ë²¨ì„ ì €ì¥í•  í´ë” ìƒì„±\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # í´ë˜ìŠ¤ ì´ë¦„ì„ ìˆ«ì IDë¡œ ë§¤í•‘ (0ë¶€í„° ì‹œì‘)\n",
    "    class_to_id = {name: i for i, name in enumerate(yolo_df['class'].unique())}\n",
    "    print(\"\\ní´ë˜ìŠ¤ ë§¤í•‘ ì •ë³´:\")\n",
    "    print(class_to_id)\n",
    "\n",
    "    print(f\"\\n'{output_dir}' í´ë”ì— YOLO ë¼ë²¨ íŒŒì¼ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "    \n",
    "    # ì´ë¯¸ì§€ ì‹ë³„ìë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ì²˜ë¦¬\n",
    "    for image_id, group in yolo_df.groupby('image_identifier'):\n",
    "        label_path = os.path.join(output_dir, f\"{image_id}.txt\")\n",
    "        \n",
    "        with open(label_path, 'w') as f:\n",
    "            for _, row in group.iterrows():\n",
    "                # ì´ë¯¸ì§€ í¬ê¸°\n",
    "                img_w, img_h = row['image_width'], row['image_height']\n",
    "                \n",
    "                # Bounding Box ì¢Œí‘œ (x, y, ë„ˆë¹„, ë†’ì´)\n",
    "                x, y, w, h = row['x'], row['y'], row['width'], row['height']\n",
    "\n",
    "                # YOLO í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ì¤‘ì‹¬ x, ì¤‘ì‹¬ y, ë„ˆë¹„, ë†’ì´) ë° ì •ê·œí™”\n",
    "                center_x = (x + w / 2) / img_w\n",
    "                center_y = (y + h / 2) / img_h\n",
    "                norm_w = w / img_w\n",
    "                norm_h = h / img_h\n",
    "                \n",
    "                # í´ë˜ìŠ¤ ID ê°€ì ¸ì˜¤ê¸°\n",
    "                class_id = class_to_id[row['class']]\n",
    "\n",
    "                # íŒŒì¼ì— ì“°ê¸°\n",
    "                f.write(f\"{class_id} {center_x:.6f} {center_y:.6f} {norm_w:.6f} {norm_h:.6f}\\n\")\n",
    "    \n",
    "    print(f\"ë¼ë²¨ íŒŒì¼ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ {len(yolo_df.groupby('image_identifier'))}ê°œì˜ íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    # YOLO í•™ìŠµ ì„¤ì •ì— í•„ìš”í•œ YAML íŒŒì¼ ë‚´ìš© ì¶œë ¥\n",
    "    print(\"\\n--- YOLO í•™ìŠµìš© YAML íŒŒì¼ì— ë‹¤ìŒ ë‚´ìš©ì„ ì¶”ê°€í•˜ì„¸ìš” ---\")\n",
    "    print(\"names:\")\n",
    "    for name, class_id in class_to_id.items():\n",
    "        print(f\"  {class_id}: {name}\")\n",
    "    print(f\"nc: {len(class_to_id)}\")\n",
    "    print(\"-------------------------------------------------\")\n",
    "\n",
    "\n",
    "# --- ë©”ì¸ ì½”ë“œ ì‹¤í–‰ ---\n",
    "if __name__ == '__main__':\n",
    "    # 1. ì›ë³¸ CSV íŒŒì¼ì—ì„œ í•„ìš”í•œ ë°ì´í„°ë§Œ ì¶”ì¶œí•˜ì—¬ DataFrame ìƒì„±\n",
    "    csv_file = 'C:/Users/breath03/Desktop/Smart_Closet/labeled_fashion_data(polygon_features).csv'\n",
    "    train_yolo_df = create_yolo_dataframe(csv_file)\n",
    "\n",
    "    # ìƒì„±ëœ DataFrame í™•ì¸ (ìƒìœ„ 5ê°œ)\n",
    "    if train_yolo_df is not None:\n",
    "        print(\"\\nìƒì„±ëœ train_yolo_df ë¯¸ë¦¬ë³´ê¸°:\")\n",
    "        print(train_yolo_df.head())\n",
    "\n",
    "        # 2. ìƒì„±ëœ DataFrameì„ ë°”íƒ•ìœ¼ë¡œ YOLO .txt ë¼ë²¨ íŒŒì¼ë“¤ ìƒì„±\n",
    "        create_yolo_label_files(train_yolo_df, output_dir='yolo_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d8c29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'C:/Users/breath03/Desktop/Smart_Closet/Training/ì›ì²œë°ì´í„°'ì™€ ëª¨ë“  í•˜ìœ„ í´ë”ì—ì„œ ì›ë³¸ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ëŠ” ì¤‘ì…ë‹ˆë‹¤...\n",
      "ì´ 643265ê°œì˜ ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n",
      "'C:/Users/breath03/Desktop/Smart_Closet/yolo_labels'ì—ì„œ ì´ 21039ê°œì˜ ë¼ë²¨ íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n",
      "\n",
      "'C:/Users/breath03/Desktop/Smart_Closet/yolo_images' í´ë”ë¡œ ì´ë¯¸ì§€ ë³µì‚¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\n",
      "1000ê°œì˜ ì´ë¯¸ì§€ ë³µì‚¬ ì™„ë£Œ...\n",
      "2000ê°œì˜ ì´ë¯¸ì§€ ë³µì‚¬ ì™„ë£Œ...\n",
      "3000ê°œì˜ ì´ë¯¸ì§€ ë³µì‚¬ ì™„ë£Œ...\n",
      "4000ê°œì˜ ì´ë¯¸ì§€ ë³µì‚¬ ì™„ë£Œ...\n",
      "5000ê°œì˜ ì´ë¯¸ì§€ ë³µì‚¬ ì™„ë£Œ...\n",
      "6000ê°œì˜ ì´ë¯¸ì§€ ë³µì‚¬ ì™„ë£Œ...\n",
      "7000ê°œì˜ ì´ë¯¸ì§€ ë³µì‚¬ ì™„ë£Œ...\n",
      "8000ê°œì˜ ì´ë¯¸ì§€ ë³µì‚¬ ì™„ë£Œ...\n",
      "9000ê°œì˜ ì´ë¯¸ì§€ ë³µì‚¬ ì™„ë£Œ...\n",
      "10000ê°œì˜ ì´ë¯¸ì§€ ë³µì‚¬ ì™„ë£Œ...\n",
      "11000ê°œì˜ ì´ë¯¸ì§€ ë³µì‚¬ ì™„ë£Œ...\n",
      "12000ê°œì˜ ì´ë¯¸ì§€ ë³µì‚¬ ì™„ë£Œ...\n",
      "13000ê°œì˜ ì´ë¯¸ì§€ ë³µì‚¬ ì™„ë£Œ...\n",
      "14000ê°œì˜ ì´ë¯¸ì§€ ë³µì‚¬ ì™„ë£Œ...\n",
      "15000ê°œì˜ ì´ë¯¸ì§€ ë³µì‚¬ ì™„ë£Œ...\n",
      "16000ê°œì˜ ì´ë¯¸ì§€ ë³µì‚¬ ì™„ë£Œ...\n",
      "17000ê°œì˜ ì´ë¯¸ì§€ ë³µì‚¬ ì™„ë£Œ...\n",
      "18000ê°œì˜ ì´ë¯¸ì§€ ë³µì‚¬ ì™„ë£Œ...\n",
      "19000ê°œì˜ ì´ë¯¸ì§€ ë³µì‚¬ ì™„ë£Œ...\n",
      "20000ê°œì˜ ì´ë¯¸ì§€ ë³µì‚¬ ì™„ë£Œ...\n",
      "21000ê°œì˜ ì´ë¯¸ì§€ ë³µì‚¬ ì™„ë£Œ...\n",
      "\n",
      "==================================================\n",
      "ğŸ‰ YOLO í•™ìŠµìš© ì´ë¯¸ì§€ í´ë” ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ‰\n",
      "ğŸ–¼ï¸  ì´ 21039ê°œì˜ ì´ë¯¸ì§€ë¥¼ 'C:/Users/breath03/Desktop/Smart_Closet/yolo_images' í´ë”ì— ë³µì‚¬í–ˆìŠµë‹ˆë‹¤.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# yoloëª¨ë¸ì— í•™ìŠµì— ì“°ì¼ ì´ë¯¸ì§€ í´ë” ìƒì„± ì½”ë“œ\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "# --- ì„¤ì • (ë°±ì§€ë¯¼ë‹˜ì´ í™•ì¸í•  ë¶€ë¶„) ---\n",
    "# 1. ì›ë³¸ ë°ì´í„° ê²½ë¡œ\n",
    "# ì´ì „ì— 'prepare_yolo_data.py'ë¥¼ ì‹¤í–‰í–ˆë˜ í´ë”ì™€ ë™ì¼í•œ ìœ„ì¹˜ì—ì„œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\n",
    "original_image_root = 'C:/Users/breath03/Desktop/Smart_Closet/Training/ì›ì²œë°ì´í„°' # ì›ë³¸ ë£© ì‚¬ì§„ë“¤ì´ ìˆëŠ” ìµœìƒìœ„ í´ë”\n",
    "label_folder = 'C:/Users/breath03/Desktop/Smart_Closet/yolo_labels'             # ì´ì „ì— ìƒì„±í•œ .txt ë¼ë²¨ íŒŒì¼ í´ë”\n",
    "\n",
    "# 2. ìƒˆë¡œ ìƒì„±ë  YOLO í•™ìŠµìš© ì´ë¯¸ì§€ í´ë”\n",
    "output_image_folder = 'C:/Users/breath03/Desktop/Smart_Closet/yolo_images'\n",
    "# -----------------------------------------\n",
    "\n",
    "def create_yolo_image_folder():\n",
    "    \"\"\"\n",
    "    ë¼ë²¨(.txt) íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ” ì´ë¯¸ì§€ë“¤ë§Œ ì›ë³¸ í´ë”ì—ì„œ ì°¾ì•„\n",
    "    ìƒˆë¡œìš´ í•™ìŠµìš© ì´ë¯¸ì§€ í´ë”ë¡œ ë³µì‚¬í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    # ê²°ê³¼ë¬¼ ì €ì¥ í´ë” ìƒì„±\n",
    "    if not os.path.exists(output_image_folder):\n",
    "        os.makedirs(output_image_folder)\n",
    "\n",
    "    # 1. ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ ë§µ ìƒì„±\n",
    "    print(f\"'{original_image_root}'ì™€ ëª¨ë“  í•˜ìœ„ í´ë”ì—ì„œ ì›ë³¸ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ëŠ” ì¤‘ì…ë‹ˆë‹¤...\")\n",
    "    if not os.path.isdir(original_image_root):\n",
    "        print(f\"ì˜¤ë¥˜: '{original_image_root}' ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "        \n",
    "    image_path_map = {}\n",
    "    for root, _, files in os.walk(original_image_root):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                identifier = os.path.splitext(file)[0]\n",
    "                image_path_map[identifier] = os.path.join(root, file)\n",
    "    print(f\"ì´ {len(image_path_map)}ê°œì˜ ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    # 2. ë¼ë²¨ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°\n",
    "    if not os.path.isdir(label_folder):\n",
    "        print(f\"ì˜¤ë¥˜: '{label_folder}' ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì´ì „ ë‹¨ê³„ì—ì„œ ë¼ë²¨ íŒŒì¼ì„ ë¨¼ì € ìƒì„±í•´ì£¼ì„¸ìš”.\")\n",
    "        return\n",
    "        \n",
    "    label_files = os.listdir(label_folder)\n",
    "    print(f\"'{label_folder}'ì—ì„œ ì´ {len(label_files)}ê°œì˜ ë¼ë²¨ íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    # 3. ì´ë¯¸ì§€ ë³µì‚¬ ì‹œì‘\n",
    "    copied_count = 0\n",
    "    print(f\"\\n'{output_image_folder}' í´ë”ë¡œ ì´ë¯¸ì§€ ë³µì‚¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "    for label_file in label_files:\n",
    "        # ë¼ë²¨ íŒŒì¼ ì´ë¦„ì—ì„œ í™•ì¥ìë¥¼ ì œê±°í•˜ì—¬ ì´ë¯¸ì§€ ì‹ë³„ì ì¶”ì¶œ (ì˜ˆ: '994962')\n",
    "        identifier = os.path.splitext(label_file)[0]\n",
    "\n",
    "        # í•´ë‹¹ ì‹ë³„ìë¥¼ ê°€ì§„ ì›ë³¸ ì´ë¯¸ì§€ê°€ ìˆëŠ”ì§€ í™•ì¸\n",
    "        if identifier in image_path_map:\n",
    "            source_path = image_path_map[identifier]\n",
    "            # ë³µì‚¬ë  íŒŒì¼ì˜ ì „ì²´ ê²½ë¡œ\n",
    "            destination_path = os.path.join(output_image_folder, os.path.basename(source_path))\n",
    "            \n",
    "            # ì´ë¯¸ì§€ íŒŒì¼ ë³µì‚¬\n",
    "            shutil.copyfile(source_path, destination_path)\n",
    "            copied_count += 1\n",
    "        \n",
    "        if (copied_count % 1000 == 0) and (copied_count > 0):\n",
    "             print(f\"{copied_count}ê°œì˜ ì´ë¯¸ì§€ ë³µì‚¬ ì™„ë£Œ...\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ğŸ‰ YOLO í•™ìŠµìš© ì´ë¯¸ì§€ í´ë” ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ‰\")\n",
    "    print(f\"ğŸ–¼ï¸  ì´ {copied_count}ê°œì˜ ì´ë¯¸ì§€ë¥¼ '{output_image_folder}' í´ë”ì— ë³µì‚¬í–ˆìŠµë‹ˆë‹¤.\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "# --- ë©”ì¸ ì½”ë“œ ì‹¤í–‰ ---\n",
    "if __name__ == '__main__':\n",
    "    create_yolo_image_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7039fc43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ ì´ë¯¸ì§€ ìˆ˜: 21039\n",
      "í•™ìŠµìš© ë°ì´í„° ìˆ˜: 16831\n",
      "ê²€ì¦ìš© ë°ì´í„° ìˆ˜: 4208\n",
      "\n",
      "'/C:/Users/breath03/Desktop/Smart_Closet/fashion_dataset/' í´ë”ì— í•™ìŠµ/ê²€ì¦ ë°ì´í„°ì…‹ ìƒì„±ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# yolo í•™ìŠµì— ì“°ì¼ ì´ë¯¸ì§€/ë¼ë²¨ í´ë”ë¥¼ í•™ìŠµ/ê²€ì¦ìš©ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ì½”ë“œ\n",
    "\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# --- ì„¤ì • ---\n",
    "# ì›ë³¸ í´ë” ê²½ë¡œ\n",
    "image_dir = 'C:/Users/breath03/Desktop/Smart_Closet/yolo_images'\n",
    "label_dir = 'C:/Users/breath03/Desktop/Smart_Closet/yolo_labels'\n",
    "\n",
    "# ìƒˆë¡œ ë§Œë“¤ í´ë” ê²½ë¡œ\n",
    "base_output_dir = 'C:/Users/breath03/Desktop/Smart_Closet/fashion_dataset'\n",
    "\n",
    "# ê²€ì¦ ë°ì´í„°ì…‹ ë¹„ìœ¨ (ì˜ˆ: 0.2 = 20%)\n",
    "val_split_ratio = 0.2\n",
    "# -----------\n",
    "\n",
    "def split_data():\n",
    "    # ì „ì²´ ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°\n",
    "    all_images = [f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png'))]\n",
    "    random.shuffle(all_images)\n",
    "\n",
    "    # í•™ìŠµìš©ê³¼ ê²€ì¦ìš©ìœ¼ë¡œ ë‚˜ëˆ„ê¸°\n",
    "    split_index = int(len(all_images) * (1 - val_split_ratio))\n",
    "    train_files = all_images[:split_index]\n",
    "    val_files = all_images[split_index:]\n",
    "\n",
    "    print(f\"ì´ ì´ë¯¸ì§€ ìˆ˜: {len(all_images)}\")\n",
    "    print(f\"í•™ìŠµìš© ë°ì´í„° ìˆ˜: {len(train_files)}\")\n",
    "    print(f\"ê²€ì¦ìš© ë°ì´í„° ìˆ˜: {len(val_files)}\")\n",
    "\n",
    "    # í´ë” ìƒì„± í•¨ìˆ˜\n",
    "    def create_dirs(base, set_name):\n",
    "        os.makedirs(os.path.join(base, 'images', set_name), exist_ok=True)\n",
    "        os.makedirs(os.path.join(base, 'labels', set_name), exist_ok=True)\n",
    "\n",
    "    # íŒŒì¼ ë³µì‚¬ í•¨ìˆ˜\n",
    "    def copy_files(files, set_name):\n",
    "        for filename in files:\n",
    "            basename = os.path.splitext(filename)[0]\n",
    "            # ì´ë¯¸ì§€ ë³µì‚¬\n",
    "            shutil.copy(os.path.join(image_dir, filename), \n",
    "                        os.path.join(base_output_dir, 'images', set_name, filename))\n",
    "            # ë¼ë²¨ ë³µì‚¬\n",
    "            shutil.copy(os.path.join(label_dir, f\"{basename}.txt\"), \n",
    "                        os.path.join(base_output_dir, 'labels', set_name, f\"{basename}.txt\"))\n",
    "\n",
    "    # í´ë” ìƒì„± ë° íŒŒì¼ ë³µì‚¬ ì‹¤í–‰\n",
    "    create_dirs(base_output_dir, 'train')\n",
    "    create_dirs(base_output_dir, 'val')\n",
    "    copy_files(train_files, 'train')\n",
    "    copy_files(val_files, 'val')\n",
    "\n",
    "    print(f\"\\n'/{base_output_dir}/' í´ë”ì— í•™ìŠµ/ê²€ì¦ ë°ì´í„°ì…‹ ìƒì„±ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    split_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295bcdb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'C:/Users/breath03/runs/detect/train5/weights/best.pt' ëª¨ë¸ì„ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.\n",
      "\n",
      "--- 'C:/Users/breath03/Desktop/Smart_Closet/IMG_3260.jpg' ì´ë¯¸ì§€ ë¶„ì„ ì‹œì‘ ---\n",
      "\n",
      "image 1/1 C:\\Users\\breath03\\Desktop\\Smart_Closet\\IMG_3260.jpg: 640x480 1 , 66.0ms\n",
      "Speed: 3.0ms preprocess, 66.0ms inference, 80.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "-> íƒì§€ëœ ê°ì²´: ì›í”¼ìŠ¤\n",
      "   ì¢Œí‘œ (x1, y1, x2, y2): [51, 174, 2866, 3788]\n",
      "   ì‹ ë¢°ë„: 0.69\n",
      "-> ë¶„ì„ ê²°ê³¼ ì´ë¯¸ì§€ë¥¼ 'test_results\\IMG_3260.jpg'ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "--- 'C:/Users/breath03/Desktop/Smart_Closet/IMG_3261.jpg' ì´ë¯¸ì§€ ë¶„ì„ ì‹œì‘ ---\n",
      "\n",
      "image 1/1 C:\\Users\\breath03\\Desktop\\Smart_Closet\\IMG_3261.jpg: 640x480 1 , 12.0ms\n",
      "Speed: 5.0ms preprocess, 12.0ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "-> íƒì§€ëœ ê°ì²´: í•˜ì˜\n",
      "   ì¢Œí‘œ (x1, y1, x2, y2): [295, 142, 2897, 3935]\n",
      "   ì‹ ë¢°ë„: 0.86\n",
      "-> ë¶„ì„ ê²°ê³¼ ì´ë¯¸ì§€ë¥¼ 'test_results\\IMG_3261.jpg'ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# yolo ëª¨ë¸ ì‹¤ì œ ì‹¤í–‰í•´ë³´ëŠ” ì½”ë“œ\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# --- ì„¤ì • (ë°±ì§€ë¯¼ë‹˜ì´ ìˆ˜ì •í•´ì•¼ í•  ë¶€ë¶„) ---\n",
    "\n",
    "# 1. í›ˆë ¨ëœ ë‚˜ë§Œì˜ ëª¨ë¸ ê²½ë¡œë¥¼ ì§€ì •í•´ì£¼ì„¸ìš”.\n",
    "# ë³´í†µ 'runs/detect/train/weights/best.pt' í˜•íƒœì…ë‹ˆë‹¤.\n",
    "# train ë’¤ì˜ ìˆ«ìëŠ” ì‹¤í–‰í•  ë•Œë§ˆë‹¤ ë°”ë€” ìˆ˜ ìˆìœ¼ë‹ˆ, í´ë”ë¥¼ ì§ì ‘ í™•ì¸í•´ë³´ì„¸ìš”.\n",
    "MODEL_PATH = 'C:/Users/breath03/runs/detect/train5/weights/best.pt' \n",
    "\n",
    "# 2. í…ŒìŠ¤íŠ¸í•˜ê³  ì‹¶ì€ ì´ë¯¸ì§€ íŒŒì¼ë“¤ì˜ ê²½ë¡œë¥¼ ë¦¬ìŠ¤íŠ¸ì— ë‹´ì•„ì£¼ì„¸ìš”.\n",
    "# ìŠ¤í¬ë¦½íŠ¸ì™€ ê°™ì€ í´ë”ì— ì´ë¯¸ì§€ë“¤ì„ ë‘ëŠ” ê²ƒì´ ê°€ì¥ ê°„ë‹¨í•©ë‹ˆë‹¤.\n",
    "IMAGE_PATHS = [\n",
    "    'C:/Users/breath03/Desktop/Smart_Closet/IMG_3260.jpg', \n",
    "    'C:/Users/breath03/Desktop/Smart_Closet/IMG_3261.jpg'\n",
    "]\n",
    "\n",
    "# 3. ê²°ê³¼ ì´ë¯¸ì§€ë¥¼ ì €ì¥í•  í´ë”\n",
    "OUTPUT_DIR = 'test_results'\n",
    "# -----------------------------------------\n",
    "\n",
    "def predict_my_clothes():\n",
    "    \"\"\"\n",
    "    í›ˆë ¨ëœ YOLO ëª¨ë¸ì„ ë¶ˆëŸ¬ì™€ ìƒˆë¡œìš´ ì´ë¯¸ì§€ë“¤ì„ ì˜ˆì¸¡í•˜ê³ ,\n",
    "    ì¢Œí‘œ ê°’ê³¼ ì‹œê°í™”ëœ ê²°ê³¼ ì´ë¯¸ì§€ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    # ê²°ê³¼ ì €ì¥ í´ë” ìƒì„±\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    # 1. í›ˆë ¨ëœ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    try:\n",
    "        model = YOLO(MODEL_PATH)\n",
    "        print(f\"'{MODEL_PATH}' ëª¨ë¸ì„ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.\")\n",
    "    except Exception as e:\n",
    "        print(f\"ì˜¤ë¥˜: ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”. ì—ëŸ¬: {e}\")\n",
    "        return\n",
    "\n",
    "    # 2. ì´ë¯¸ì§€ë“¤ì„ í•˜ë‚˜ì”© ëª¨ë¸ì— ë„£ì–´ ì˜ˆì¸¡ ì‹¤í–‰\n",
    "    for img_path in IMAGE_PATHS:\n",
    "        if not os.path.exists(img_path):\n",
    "            print(f\"ê²½ê³ : '{img_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n--- '{img_path}' ì´ë¯¸ì§€ ë¶„ì„ ì‹œì‘ ---\")\n",
    "        \n",
    "        # ëª¨ë¸ ì˜ˆì¸¡\n",
    "        results = model(img_path)\n",
    "\n",
    "        # 3. ê²°ê³¼ì—ì„œ ì¢Œí‘œ ê°’ê³¼ ì •ë³´ ì¶”ì¶œí•˜ê¸°\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "            if len(boxes) == 0:\n",
    "                print(\"-> íƒì§€ëœ ê°ì²´ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "                continue\n",
    "\n",
    "            for box in boxes:\n",
    "                # í´ë˜ìŠ¤ ì´ë¦„ (ìƒì˜, í•˜ì˜ ë“±)\n",
    "                class_name = model.names[int(box.cls[0])]\n",
    "                \n",
    "                # ì¢Œí‘œ ê°’ (x1, y1, x2, y2)\n",
    "                coordinates = [int(x) for x in box.xyxy[0].tolist()]\n",
    "                \n",
    "                # ì‹ ë¢°ë„ ì ìˆ˜ (ëª¨ë¸ì´ ì–¼ë§ˆë‚˜ í™•ì‹ í•˜ëŠ”ì§€)\n",
    "                confidence = float(box.conf[0])\n",
    "                \n",
    "                # í„°ë¯¸ë„ì— ê²°ê³¼ ì¶œë ¥\n",
    "                print(f\"-> íƒì§€ëœ ê°ì²´: {class_name}\")\n",
    "                print(f\"   ì¢Œí‘œ (x1, y1, x2, y2): {coordinates}\")\n",
    "                print(f\"   ì‹ ë¢°ë„: {confidence:.2f}\") # ì†Œìˆ˜ì  2ìë¦¬ê¹Œì§€\n",
    "        \n",
    "        # 4. ì‹œê°í™”ëœ ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥í•˜ê¸°\n",
    "        # results ê°ì²´ì˜ plot() ë©”ì†Œë“œëŠ” ë°”ìš´ë”© ë°•ìŠ¤ê°€ ê·¸ë ¤ì§„ ì´ë¯¸ì§€ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "        result_image_array = r.plot() \n",
    "        result_image = Image.fromarray(result_image_array[..., ::-1]) # BGR -> RGB ë³€í™˜\n",
    "        \n",
    "        output_path = os.path.join(OUTPUT_DIR, os.path.basename(img_path))\n",
    "        result_image.save(output_path)\n",
    "        print(f\"-> ë¶„ì„ ê²°ê³¼ ì´ë¯¸ì§€ë¥¼ '{output_path}'ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    predict_my_clothes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dc32a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'./labeled_fashion_data(polygon_features).csv' íŒŒì¼ì„ ì½ëŠ” ì¤‘ì…ë‹ˆë‹¤...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_18456\\3795998490.py:29: DtypeWarning: Columns (26,63) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'./Training/ì›ì²œë°ì´í„°'ì™€ ëª¨ë“  í•˜ìœ„ í´ë”ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ëŠ” ì¤‘ì…ë‹ˆë‹¤...\n",
      "ì´ 643265ê°œì˜ ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n",
      "ì´ 41240ê°œì˜ CSV ë°ì´í„° ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\n",
      "ì§„í–‰ ìƒí™©: 1000 / 41240\n",
      "ì§„í–‰ ìƒí™©: 2000 / 41240\n",
      "ì§„í–‰ ìƒí™©: 3000 / 41240\n",
      "ì§„í–‰ ìƒí™©: 4000 / 41240\n",
      "ì§„í–‰ ìƒí™©: 5000 / 41240\n",
      "ì§„í–‰ ìƒí™©: 6000 / 41240\n",
      "ì§„í–‰ ìƒí™©: 7000 / 41240\n",
      "ì§„í–‰ ìƒí™©: 8000 / 41240\n",
      "ì§„í–‰ ìƒí™©: 9000 / 41240\n",
      "ì§„í–‰ ìƒí™©: 10000 / 41240\n",
      "ì§„í–‰ ìƒí™©: 11000 / 41240\n",
      "ì§„í–‰ ìƒí™©: 12000 / 41240\n",
      "ì§„í–‰ ìƒí™©: 13000 / 41240\n",
      "ì§„í–‰ ìƒí™©: 14000 / 41240\n",
      "ì§„í–‰ ìƒí™©: 15000 / 41240\n",
      "ì§„í–‰ ìƒí™©: 16000 / 41240\n",
      "ì§„í–‰ ìƒí™©: 17000 / 41240\n",
      "ì§„í–‰ ìƒí™©: 18000 / 41240\n",
      "ì§„í–‰ ìƒí™©: 19000 / 41240\n",
      "ì§„í–‰ ìƒí™©: 20000 / 41240\n",
      "ì§„í–‰ ìƒí™©: 21000 / 41240\n",
      "ì§„í–‰ ìƒí™©: 22000 / 41240\n",
      "ì§„í–‰ ìƒí™©: 23000 / 41240\n",
      "ì§„í–‰ ìƒí™©: 24000 / 41240\n",
      "ì§„í–‰ ìƒí™©: 25000 / 41240\n",
      "ì§„í–‰ ìƒí™©: 26000 / 41240\n",
      "ì§„í–‰ ìƒí™©: 27000 / 41240\n",
      "ì§„í–‰ ìƒí™©: 28000 / 41240\n",
      "ì§„í–‰ ìƒí™©: 29000 / 41240\n",
      "ì§„í–‰ ìƒí™©: 30000 / 41240\n",
      "ì§„í–‰ ìƒí™©: 31000 / 41240\n",
      "ì§„í–‰ ìƒí™©: 32000 / 41240\n",
      "ì§„í–‰ ìƒí™©: 33000 / 41240\n",
      "ì§„í–‰ ìƒí™©: 34000 / 41240\n",
      "ì§„í–‰ ìƒí™©: 35000 / 41240\n",
      "ì§„í–‰ ìƒí™©: 36000 / 41240\n",
      "ì§„í–‰ ìƒí™©: 37000 / 41240\n",
      "ì§„í–‰ ìƒí™©: 38000 / 41240\n",
      "ì§„í–‰ ìƒí™©: 39000 / 41240\n",
      "ì§„í–‰ ìƒí™©: 40000 / 41240\n",
      "ì§„í–‰ ìƒí™©: 41000 / 41240\n",
      "\n",
      "==================================================\n",
      "ğŸ‰ ë°ì´í„°ì…‹ ìƒì„±ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ‰\n",
      "ğŸ–¼ï¸  ì˜ë¼ë‚¸ ì´ë¯¸ì§€ë“¤ì€ './cropped_images' í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "ğŸ“Š ìƒˆë¡œìš´ ë©”íƒ€ë°ì´í„°ëŠ” './cropped_images_metadata.csv' íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "ì´ 64387ê°œì˜ ìƒˆë¡œìš´ ê°œë³„ ì˜· ë°ì´í„°ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# ë£© ì´ë¯¸ì§€ì—ì„œ ê°œë³„ ì˜· ì´ë¯¸ì§€ë¥¼ ì˜ë¼ë‚´ê³  ìƒˆë¡œìš´ datasetì„ ìƒì„±í•˜ëŠ” ìµœì¢… ìŠ¤í¬ë¦½íŠ¸\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# --- ì„¤ì • (ë°±ì§€ë¯¼ë‹˜ì´ í™•ì¸í•  ë¶€ë¶„) ---\n",
    "# 1. ì›ë³¸ ë°ì´í„° ê²½ë¡œ\n",
    "csv_path = './labeled_fashion_data(polygon_features).csv'\n",
    "image_root_folder = './Training/ì›ì²œë°ì´í„°'\n",
    "\n",
    "# 2. ìƒˆë¡œ ìƒì„±ë  ë°ì´í„°ì…‹ì„ ì €ì¥í•  ê²½ë¡œ\n",
    "output_image_folder = './cropped_images'\n",
    "new_metadata_csv_path = './cropped_images_metadata.csv'\n",
    "# -----------------------------------------\n",
    "\n",
    "def create_dataset_final():\n",
    "    \"\"\"\n",
    "    'ì´ë¯¸ì§€ ì‹ë³„ì'ë¥¼ í‚¤ë¡œ ì‚¬ìš©í•˜ì—¬ í•˜ìœ„ í´ë”ê¹Œì§€ íƒìƒ‰í•´ ì´ë¯¸ì§€ë¥¼ ì°¾ê³ ,\n",
    "    ë°ì´í„°ì…‹ì„ ìƒì„±í•˜ëŠ” ìµœì¢… ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    # ê²°ê³¼ë¬¼ ì €ì¥ í´ë” ìƒì„±\n",
    "    if not os.path.exists(output_image_folder):\n",
    "        os.makedirs(output_image_folder)\n",
    "\n",
    "    # CSV íŒŒì¼ ì½ê¸°\n",
    "    print(f\"'{csv_path}' íŒŒì¼ì„ ì½ëŠ” ì¤‘ì…ë‹ˆë‹¤...\")\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ì˜¤ë¥˜: '{csv_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìŠ¤í¬ë¦½íŠ¸ì™€ CSV íŒŒì¼ì´ ê°™ì€ ìœ„ì¹˜ì— ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "        return\n",
    "\n",
    "    # ì´ë¯¸ì§€ ê²½ë¡œ ë§µ ìƒì„± (ë§¤ìš° ì¤‘ìš”!)\n",
    "    # 'ì›ì²œë°ì´í„°' í´ë”ì™€ ê·¸ ì•ˆì˜ ëª¨ë“  í•˜ìœ„ í´ë”ë¥¼ íƒìƒ‰í•˜ì—¬\n",
    "    # 'ì´ë¯¸ì§€ ì‹ë³„ì'ë¥¼ í‚¤ë¡œ, ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¥¼ ê°’ìœ¼ë¡œ í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ë¥¼ ë§Œë“­ë‹ˆë‹¤.\n",
    "    print(f\"'{image_root_folder}'ì™€ ëª¨ë“  í•˜ìœ„ í´ë”ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ëŠ” ì¤‘ì…ë‹ˆë‹¤...\")\n",
    "    if not os.path.isdir(image_root_folder):\n",
    "        print(f\"ì˜¤ë¥˜: '{image_root_folder}' ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "        \n",
    "    image_path_map = {}\n",
    "    for root, _, files in os.walk(image_root_folder):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                # íŒŒì¼ ì´ë¦„ì—ì„œ í™•ì¥ìë¥¼ ì œê±°í•œ ë¶€ë¶„ì„ í‚¤ë¡œ ì‚¬ìš© (ì˜ˆ: '994962')\n",
    "                identifier = os.path.splitext(file)[0]\n",
    "                image_path_map[identifier] = os.path.join(root, file)\n",
    "    print(f\"ì´ {len(image_path_map)}ê°œì˜ ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    # ìƒˆ ë©”íƒ€ë°ì´í„° ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”\n",
    "    new_metadata_list = []\n",
    "    total_rows = df.shape[0]\n",
    "    print(f\"ì´ {total_rows}ê°œì˜ CSV ë°ì´í„° ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "\n",
    "    # ë°ì´í„°í”„ë ˆì„ ìˆœíšŒ\n",
    "    for index, row in df.iterrows():\n",
    "        if (index + 1) % 1000 == 0:\n",
    "            print(f\"ì§„í–‰ ìƒí™©: {index + 1} / {total_rows}\")\n",
    "\n",
    "        # 'ì´ë¯¸ì§€ ì‹ë³„ì'ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ í‚¤ë¡œ ì‚¬ìš©\n",
    "        identifier_key = str(row['ì´ë¯¸ì§€ ì‹ë³„ì'])\n",
    "\n",
    "        # ë§µì—ì„œ í•´ë‹¹ ì‹ë³„ìë¥¼ ê°€ì§„ ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì°¾ìŒ\n",
    "        if identifier_key not in image_path_map:\n",
    "            continue # ì´ë¯¸ì§€ë¥¼ ì°¾ì§€ ëª»í•˜ë©´ ê±´ë„ˆë›°ê¸°\n",
    "\n",
    "        original_image_path = image_path_map[identifier_key]\n",
    "        try:\n",
    "            original_image = Image.open(original_image_path)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        style = row['ìŠ¤íƒ€ì¼_ìŠ¤íƒ€ì¼']\n",
    "        # ìƒˆ íŒŒì¼ ì´ë¦„ì— 'ì´ë¯¸ì§€ ì‹ë³„ì'ë¥¼ ì‚¬ìš©í•˜ì—¬ ë” ëª…í™•í•˜ê²Œ ë§Œë“¦\n",
    "        base_name = identifier_key \n",
    "\n",
    "        item_types = {'ìƒì˜': 'top', 'í•˜ì˜': 'bottom', 'ì•„ìš°í„°': 'outer', 'ì›í”¼ìŠ¤': 'onepiece'}\n",
    "\n",
    "        for kor_type, eng_type in item_types.items():\n",
    "            x_col, y_col, w_col, h_col = f'{kor_type}_ë ‰íŠ¸_Xì¢Œí‘œ', f'{kor_type}_ë ‰íŠ¸_Yì¢Œí‘œ', f'{kor_type}_ë ‰íŠ¸_ê°€ë¡œ', f'{kor_type}_ë ‰íŠ¸_ì„¸ë¡œ'\n",
    "            cat_col = f'{kor_type}_ë¼ë²¨_ì¹´í…Œê³ ë¦¬'\n",
    "\n",
    "            if x_col in row and row.get(x_col, 0) > 0 and pd.notna(row.get(cat_col)):\n",
    "                x, y, w, h = row[x_col], row[y_col], row[w_col], row[h_col]\n",
    "                category = row[cat_col]\n",
    "                bbox = (x, y, x + w, y + h)\n",
    "                \n",
    "                width, height = original_image.size\n",
    "                if not (0 <= bbox[0] < bbox[2] <= width and 0 <= bbox[1] < bbox[3] <= height):\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    cropped_image = original_image.crop(bbox)\n",
    "                    # íŒŒì¼ ì´ë¦„ í˜•ì‹: {ì´ë¯¸ì§€ì‹ë³„ì}_{ì˜·ì¢…ë¥˜}_{CSVí–‰ë²ˆí˜¸}.jpg\n",
    "                    new_image_name = f\"{base_name}_{eng_type}_{index}.jpg\"\n",
    "                    cropped_image_path = os.path.join(output_image_folder, new_image_name)\n",
    "                    cropped_image.save(cropped_image_path)\n",
    "                    new_metadata_list.append({\n",
    "                        'image_name': new_image_name, 'category': category,\n",
    "                        'style': style, 'original_image_identifier': base_name\n",
    "                    })\n",
    "                except Exception:\n",
    "                    continue\n",
    "\n",
    "    # ìµœì¢… ê²°ê³¼ ì €ì¥ ë° ì¶œë ¥\n",
    "    if not new_metadata_list:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"âš ï¸ ì²˜ë¦¬ëœ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ìŒì„ í™•ì¸í•´ì£¼ì„¸ìš”:\")\n",
    "        print(\"1. CSVì˜ 'ì´ë¯¸ì§€ ì‹ë³„ì'ì™€ ì‹¤ì œ ì´ë¯¸ì§€ íŒŒì¼ ì´ë¦„(í™•ì¥ì ì œì™¸)ì´ ì¼ì¹˜í•˜ëŠ”ì§€\")\n",
    "        print(\"2. 'Training/ì›ì²œë°ì´í„°' í´ë” ì•ˆì— ë£© ìŠ¤íƒ€ì¼ë³„ í•˜ìœ„ í´ë”ì™€ ì´ë¯¸ì§€ë“¤ì´ ìˆëŠ”ì§€\")\n",
    "        print(\"=\"*50)\n",
    "        return\n",
    "\n",
    "    new_df = pd.DataFrame(new_metadata_list)\n",
    "    new_df.to_csv(new_metadata_csv_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ğŸ‰ ë°ì´í„°ì…‹ ìƒì„±ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ‰\")\n",
    "    print(f\"ğŸ–¼ï¸  ì˜ë¼ë‚¸ ì´ë¯¸ì§€ë“¤ì€ '{output_image_folder}' í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    print(f\"ğŸ“Š ìƒˆë¡œìš´ ë©”íƒ€ë°ì´í„°ëŠ” '{new_metadata_csv_path}' íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    print(f\"ì´ {len(new_metadata_list)}ê°œì˜ ìƒˆë¡œìš´ ê°œë³„ ì˜· ë°ì´í„°ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    create_dataset_final()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bebb1033",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\breath03\\Desktop\\Smart_Closet\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8940' max='8940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8940/8940 1:12:46, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Category Accuracy</th>\n",
       "      <th>Style Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.975800</td>\n",
       "      <td>0.945912</td>\n",
       "      <td>0.863751</td>\n",
       "      <td>0.856199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.392500</td>\n",
       "      <td>0.538363</td>\n",
       "      <td>0.921020</td>\n",
       "      <td>0.915041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.158300</td>\n",
       "      <td>0.466980</td>\n",
       "      <td>0.942417</td>\n",
       "      <td>0.929515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.050300</td>\n",
       "      <td>0.408854</td>\n",
       "      <td>0.948395</td>\n",
       "      <td>0.941787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.012300</td>\n",
       "      <td>0.396294</td>\n",
       "      <td>0.952486</td>\n",
       "      <td>0.947451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ í›ˆë ¨ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ëª¨ë¸ì´ '{OUTPUT_DIR}' í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ViT ëª¨ë¸ì„ finetuningí•˜ëŠ” ì½”ë“œ\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from transformers import (\n",
    "    AutoImageProcessor,\n",
    "    AutoModel,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "\n",
    "# --- ì„¤ì • ---\n",
    "CSV_PATH = 'cropped_images_metadata.csv'\n",
    "IMAGE_DIR = 'cropped_images'\n",
    "MODEL_NAME = \"google/vit-base-patch16-224-in21k\"\n",
    "OUTPUT_DIR = \"fashion_classifier_model\"\n",
    "# ------------\n",
    "\n",
    "# 1. ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜\n",
    "class FashionDataset(Dataset):\n",
    "    def __init__(self, csv_path, image_dir, processor):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.image_dir = image_dir\n",
    "        self.processor = processor\n",
    "        \n",
    "        # ì¹´í…Œê³ ë¦¬ì™€ ìŠ¤íƒ€ì¼ ë¼ë²¨ì„ ìˆ«ìë¡œ ë³€í™˜ (Label Encoding)\n",
    "        self.category_labels = self.df['category'].astype('category').cat.codes\n",
    "        self.style_labels = self.df['style'].astype('category').cat.codes\n",
    "        \n",
    "        # ë‚˜ì¤‘ì— ìˆ«ìë¥¼ ë‹¤ì‹œ ì›ë˜ ì´ë¦„ìœ¼ë¡œ ë°”ê¾¸ê¸° ìœ„í•´ ë§¤í•‘ ì •ë³´ ì €ì¥\n",
    "        self.id2cat = dict(enumerate(self.df['category'].astype('category').cat.categories))\n",
    "        self.id2style = dict(enumerate(self.df['style'].astype('category').cat.categories))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image_path = os.path.join(self.image_dir, row['image_name'])\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        \n",
    "        # ì´ë¯¸ì§€ë¥¼ ëª¨ë¸ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë³€í™˜\n",
    "        inputs = self.processor(images=image, return_tensors=\"pt\")\n",
    "        \n",
    "        return {\n",
    "            \"pixel_values\": inputs.pixel_values.squeeze(),\n",
    "            \"category_labels\": torch.tensor(self.category_labels[idx], dtype=torch.long),\n",
    "            \"style_labels\": torch.tensor(self.style_labels[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# 2. Multi-Task ëª¨ë¸ ì„¤ê³„\n",
    "class MultiTaskClassifier(nn.Module):\n",
    "    def __init__(self, num_categories, num_styles):\n",
    "        super().__init__()\n",
    "        self.body = AutoModel.from_pretrained(MODEL_NAME)\n",
    "        hidden_size = self.body.config.hidden_size\n",
    "        self.category_head = nn.Linear(hidden_size, num_categories)\n",
    "        self.style_head = nn.Linear(hidden_size, num_styles)\n",
    "\n",
    "    def forward(self, pixel_values, category_labels=None, style_labels=None):\n",
    "        features = self.body(pixel_values=pixel_values).last_hidden_state[:, 0, :]\n",
    "        \n",
    "        category_logits = self.category_head(features)\n",
    "        style_logits = self.style_head(features)\n",
    "\n",
    "        # í›ˆë ¨ ì‹œì—ëŠ” ë‘ ê°œì˜ lossë¥¼ ê³„ì‚°í•˜ì—¬ í•©ì¹¨\n",
    "        if category_labels is not None and style_labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss_category = loss_fct(category_logits, category_labels)\n",
    "            loss_style = loss_fct(style_logits, style_labels)\n",
    "            total_loss = loss_category + loss_style\n",
    "            return {\"loss\": total_loss, \"category_logits\": category_logits, \"style_logits\": style_logits}\n",
    "        \n",
    "        return {\"category_logits\": category_logits, \"style_logits\": style_logits}\n",
    "\n",
    "# 3. Multi-Task Trainer ì •ì˜ (ë‘ ê°œì˜ ì¶œë ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•¨)\n",
    "class MultiTaskTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        outputs = model(**inputs)\n",
    "        return (outputs['loss'], outputs) if return_outputs else outputs['loss']\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    category_logits, style_logits = eval_pred.predictions\n",
    "    category_labels, style_labels = eval_pred.label_ids\n",
    "\n",
    "    cat_preds = np.argmax(category_logits, axis=1)\n",
    "    style_preds = np.argmax(style_logits, axis=1)\n",
    "\n",
    "    return {\n",
    "        'category_accuracy': accuracy_score(category_labels, cat_preds),\n",
    "        'style_accuracy': accuracy_score(style_labels, style_preds)\n",
    "    }\n",
    "\n",
    "# --- ë©”ì¸ ì‹¤í–‰ ---\n",
    "if __name__ == '__main__':\n",
    "    # ë°ì´í„°ì…‹ ì¤€ë¹„\n",
    "    processor = AutoImageProcessor.from_pretrained(MODEL_NAME)\n",
    "    full_dataset = FashionDataset(CSV_PATH, IMAGE_DIR, processor)\n",
    "    \n",
    "    # ë°ì´í„°ì…‹ì„ í›ˆë ¨ìš©ê³¼ í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ë¶„ë¦¬ (9:1)\n",
    "    train_size = int(0.9 * len(full_dataset))\n",
    "    test_size = len(full_dataset) - train_size\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "    # ëª¨ë¸ ìƒì„±\n",
    "    num_categories = len(full_dataset.id2cat)\n",
    "    num_styles = len(full_dataset.id2style)\n",
    "    model = MultiTaskClassifier(num_categories, num_styles)\n",
    "\n",
    "    # í›ˆë ¨ ê·œì¹™ ì„¤ì •\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=OUTPUT_DIR,\n",
    "        per_device_train_batch_size=16,\n",
    "        eval_strategy=\"epoch\",\n",
    "        num_train_epochs=5, # ì—í¬í¬ëŠ” í•„ìš”ì— ë”°ë¼ ì¡°ì ˆ\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_steps=100,\n",
    "        load_best_model_at_end=True,\n",
    "    )\n",
    "\n",
    "    # í›ˆë ¨ ê´€ë¦¬ì ìƒì„±\n",
    "    trainer = MultiTaskTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    # í›ˆë ¨ ì‹œì‘!\n",
    "    trainer.train()\n",
    "\n",
    "    # í›ˆë ¨ëœ ëª¨ë¸ê³¼ ë¼ë²¨ ì •ë³´ ì €ì¥\n",
    "    trainer.save_model(OUTPUT_DIR)\n",
    "    torch.save({\n",
    "        'id2cat': full_dataset.id2cat,\n",
    "        'id2style': full_dataset.id2style\n",
    "    }, os.path.join(OUTPUT_DIR, 'label_maps.pth'))\n",
    "\n",
    "    print(\"ğŸ‰ í›ˆë ¨ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ëª¨ë¸ì´ '{OUTPUT_DIR}' í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d4b15dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "90100\n"
     ]
    }
   ],
   "source": [
    "# print(train_df.shape)\n",
    "# print(train_df.head())\n",
    "# print(train_df.isnull().sum())\n",
    "# print(train_yolo_df.head())\n",
    "import torch\n",
    "# print(torch.cuda.is_available())\n",
    "print(torch.backends.cudnn.is_available())\n",
    "print(torch.backends.cudnn.version())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
