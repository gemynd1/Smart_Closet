# train_router.py

import pandas as pd
import torch
from torch.utils.data import Dataset
from PIL import Image
from transformers import (
    AutoImageProcessor,
    AutoModelForImageClassification,
    TrainingArguments,
    Trainer
)
from sklearn.metrics import accuracy_score
import numpy as np
import os

# --- ì„¤ì • ---
CSV_PATH = './cropped_images_metadata.csv'
IMAGE_DIR = './cropped_images'
MODEL_NAME = "google/vit-base-patch16-224-in21k"
OUTPUT_DIR = "./router_model"
# ------------

# ë°ì´í„°ì…‹ í´ë˜ìŠ¤
class RouterDataset(Dataset):
    def __init__(self, csv_path, image_dir, processor):
        self.df = pd.read_csv(csv_path)
        self.image_dir = image_dir
        self.processor = processor
        
        # --- *** í•µì‹¬ ìˆ˜ì • ë¶€ë¶„ *** ---
        # í´ë˜ìŠ¤ ì´ë¦„ ì •ì˜ (ì˜ì–´ -> í•œê¸€)
        self.class_map = {'top': 'ìƒì˜', 'bottom': 'í•˜ì˜', 'outer': 'ì•„ìš°í„°', 'onepiece': 'ì›í”¼ìŠ¤'}
        
        # 'category' ì»¬ëŸ¼ ëŒ€ì‹ , 'image_name'ì—ì„œ ì§„ì§œ ë©”ì¸ ì¹´í…Œê³ ë¦¬ë¥¼ ì¶”ì¶œí•˜ì—¬ ë¼ë²¨ë¡œ ì‚¬ìš©
        # ì˜ˆ: 'look1_outer_0.jpg' -> 'outer' ì¶”ì¶œ -> 'ì•„ìš°í„°'ë¡œ ë³€í™˜
        self.df['main_category'] = self.df['image_name'].apply(
            lambda x: self.class_map.get(x.split('_')[-2], 'ê¸°íƒ€')
        )
        # ---------------------------

        # ìƒˆë¡œìš´ main_categoryë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìˆ«ìë¡œ ë³€í™˜
        self.labels = self.df['main_category'].astype('category').cat.codes
        self.id2label = dict(enumerate(self.df['main_category'].astype('category').cat.categories))
        self.label2id = {v: k for k, v in self.id2label.items()}

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        image_path = os.path.join(self.image_dir, row['image_name'])
        try:
            image = Image.open(image_path).convert("RGB")
        except (FileNotFoundError, OSError):
            return self.__getitem__((idx + 1) % len(self))
            
        inputs = self.processor(images=image, return_tensors="pt")
        
        return {
            "pixel_values": inputs.pixel_values.squeeze(),
            "labels": torch.tensor(self.labels[idx], dtype=torch.long)
        }

# (ì´í•˜ ì½”ë“œëŠ” ì´ì „ê³¼ ë™ì¼)
def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    preds = np.argmax(predictions, axis=1)
    return {'accuracy': accuracy_score(labels, preds)}

if __name__ == '__main__':
    processor = AutoImageProcessor.from_pretrained(MODEL_NAME)
    full_dataset = RouterDataset(CSV_PATH, IMAGE_DIR, processor)
    
    train_size = int(0.9 * len(full_dataset))
    test_size = len(full_dataset) - train_size
    train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])

    model = AutoModelForImageClassification.from_pretrained(
        MODEL_NAME, 
        num_labels=len(full_dataset.id2label),
        id2label=full_dataset.id2label,
        label2id=full_dataset.label2id
    )

    training_args = TrainingArguments(
        output_dir=OUTPUT_DIR,
        per_device_train_batch_size=16,
        num_train_epochs=3,
        logging_steps=50,
        save_strategy="epoch",
        eval_strategy="epoch",
        load_best_model_at_end=True,
    )

    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=test_dataset,
        compute_metrics=compute_metrics,
        tokenizer=processor,
    )

    print("1ì°¨ ë¶„ë¥˜ê¸° (Router Model) ì¬í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    trainer.train()
    trainer.save_model(OUTPUT_DIR)
    print(f"ğŸ‰ 1ì°¨ ë¶„ë¥˜ê¸° ì¬í›ˆë ¨ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ëª¨ë¸ì´ '{OUTPUT_DIR}' í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")